"""
è‡ªå®šä¹‰æ¨ç†å‡½æ•° - ä½¿ç”¨æˆ‘ä»¬çš„ API ä¸­è½¬ï¼Œä½†è¿”å› KernelBench å…¼å®¹çš„æ ¼å¼
"""
import time
from openai import OpenAI
from .config import API_BASE_URL, API_KEY


def create_custom_inference_function(model_id, temperature=0.0, max_tokens=4096, verbose=False):
    """
    åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰æ¨ç†å‡½æ•°ï¼Œå…¼å®¹ KernelBench çš„æ¥å£

    Args:
        model_id: æ¨¡å‹ ID
        temperature: æ¸©åº¦å‚æ•°
        max_tokens: æœ€å¤§ token æ•°
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯

    Returns:
        inference_fn: æ¨ç†å‡½æ•°ï¼Œæ¥å— prompt è¿”å›ç”Ÿæˆçš„æ–‡æœ¬
    """
    client = OpenAI(
        base_url=API_BASE_URL,
        api_key=API_KEY,
    )

    def inference_fn(prompt: str) -> str:
        """
        æ¨ç†å‡½æ•°

        Args:
            prompt: è¾“å…¥æç¤ºè¯

        Returns:
            str: ç”Ÿæˆçš„æ–‡æœ¬
        """
        if verbose:
            print(f"ğŸ¤– è°ƒç”¨æ¨¡å‹: {model_id}")
            print(f"ğŸ“ Prompt é•¿åº¦: {len(prompt)} å­—ç¬¦")

        start_time = time.time()

        try:
            response = client.chat.completions.create(
                model=model_id,
                messages=[
                    {
                        "role": "system",
                        "content": "You are an expert GPU programmer specializing in CUDA kernel optimization."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=temperature,
                max_tokens=max_tokens,
            )

            generated_text = response.choices[0].message.content
            elapsed_time = time.time() - start_time

            if verbose:
                print(f"âœ… ç”ŸæˆæˆåŠŸ! è€—æ—¶: {elapsed_time:.2f}s")
                print(f"ğŸ“Š ç”Ÿæˆé•¿åº¦: {len(generated_text)} å­—ç¬¦")

            return generated_text

        except Exception as e:
            if verbose:
                print(f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}")
            raise e

    return inference_fn
